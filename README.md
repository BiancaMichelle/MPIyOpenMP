# ğŸ´â€â˜ ï¸ Torneo One Piece - Simulador MPI/OpenMP

## ğŸ“‘ Ãndice

### ğŸš€ Parte I: GuÃ­a de Usuario
- [DescripciÃ³n y CaracterÃ­sticas](#descripciÃ³n)
- [Estructura del Proyecto](#estructura)
- [Inicio RÃ¡pido](#-inicio-rÃ¡pido)
- [CÃ³mo Usar la AplicaciÃ³n](#-cÃ³mo-usar)
- [Comandos Disponibles](#-comandos-disponibles)
- [Ejemplo Completo de Uso](#-ejemplo-completo-de-uso)
- [SoluciÃ³n de Problemas](#-soluciÃ³n-de-problemas)
- [CaracterÃ­sticas TÃ©cnicas](#-caracterÃ­sticas-tÃ©cnicas)

### ğŸ“š Parte II: Informe TÃ©cnico
- [Conceptos Demostrados](#-conceptos-demostrados)
- [TeorÃ­a: MPI (Message Passing Interface)](#-teorÃ­a-mpi-message-passing-interface)
- [TeorÃ­a: OpenMP (Open Multi-Processing)](#-teorÃ­a-openmp-open-multi-processing)
- [Arquitectura HÃ­brida del Proyecto](#-arquitectura-hÃ­brida-del-proyecto)
- [AnÃ¡lisis de Rendimiento](#-anÃ¡lisis-de-rendimiento)

---

## DescripciÃ³n
Una **aplicaciÃ³n web interactiva** que demuestra conceptos de programaciÃ³n paralela a travÃ©s de una simulaciÃ³n de torneo de personajes de One Piece. 

### âœ¨ CaracterÃ­sticas:
- ğŸŒ **Interfaz Web Moderna**: Totalmente visual, sin comandos
- âš¡ **MPI**: SimulaciÃ³n de procesos distribuidos  
- ğŸ”„ **OpenMP**: SimulaciÃ³n de memoria compartida
- ğŸ“± **Responsive**: Funciona en mÃ³viles y escritorio
- ğŸ® **Interactivo**: Selecciona tripulaciones y ve resultados en tiempo real

## Estructura
```
torneo/
â”œâ”€â”€ web/
â”‚   â”œâ”€â”€ templates/demo.html   # ğŸ® AplicaciÃ³n principal
â”‚   â”œâ”€â”€ static/               # ğŸ¨ Estilos y recursos
â”‚   â””â”€â”€ server.py            # ğŸŒ Servidor web simple
â”œâ”€â”€ src/torneo_onepiece.c     # âš™ï¸ Motor de simulaciÃ³n C
â”œâ”€â”€ config/config.json        # âš™ï¸ ConfiguraciÃ³n
â””â”€â”€ Makefile                  # ğŸ”§ Sistema de construcciÃ³n
```

## ğŸš€ Inicio RÃ¡pido

### Para Windows

#### 1. Instalar WSL
```powershell
# En PowerShell como administrador
wsl --install -d Ubuntu-22.04
```

#### 2. Instalar Dependencias
```bash
# Entrar a WSL
wsl

# Navegar al proyecto
cd /mnt/c/Users/[TU_USUARIO]/Desktop/MPIyOpenMP/torneo

# Instalar dependencias
sudo apt update && sudo apt install -y libopenmpi-dev libcjson-dev python3 make gcc
```

#### 3. Compilar y Ejecutar
```bash
# Compilar motor de simulaciÃ³n
make compile

# Iniciar aplicaciÃ³n web
make web
```

#### 4. Usar la AplicaciÃ³n
Abre tu navegador en: **http://localhost:8000/templates/demo.html**
(o el enlace que te salga por consola)

## ğŸ® CÃ³mo Usar

1. **Seleccionar Tripulaciones**: Haz clic en las tarjetas de tripulaciones
2. **Configurar Torneo**: Elige las tripulaciones que participarÃ¡n  
3. **Iniciar SimulaciÃ³n**: Presiona "Iniciar SimulaciÃ³n"
4. **Ver Resultados**: Los resultados aparecen en un modal

## ğŸ”§ Comandos Disponibles

| Comando | DescripciÃ³n |
|---------|-------------|
| `make compile` | Compila el motor de simulaciÃ³n |
| `make web` | Inicia la aplicaciÃ³n web |
| `make run` | Ejecuta simulaciÃ³n en terminal |
| `make clean` | Limpia archivos compilados |
| `make help` | Muestra ayuda |

## âš¡ Conceptos Demostrados

### MPI (Message Passing Interface)
- **Procesos Distribuidos**: Cada tripulaciÃ³n se simula en un proceso independiente
- **ComunicaciÃ³n**: Los procesos intercambian resultados para determinar el ganador

### OpenMP (Open Multi-Processing)  
- **ParalelizaciÃ³n**: Los combates dentro de cada tripulaciÃ³n se procesan en paralelo
- **Memoria Compartida**: Los hilos trabajan sobre los mismos datos


## ğŸ“ Ejemplo Completo de Uso

### Primera vez (instalaciÃ³n completa)
```bash
# 1. Desde PowerShell como administrador
wsl --install -d Ubuntu-22.04
# [Reiniciar computadora]

# 2. Abrir PowerShell normal y entrar a WSL
wsl

# 3. Navegar al proyecto
cd /mnt/c/Users/[TU_USUARIO]/Desktop/MPIyOpenMP/torneo

# 4. Instalar dependencias
sudo apt update && sudo apt install -y libopenmpi-dev libcjson-dev python3 make gcc

# 5. Compilar y ejecutar
make compile
make web
```

### Uso diario (ya instalado)
```bash
# 1. Abrir PowerShell y entrar a WSL
wsl

# 2. Ir al proyecto
cd /mnt/c/Users/[TU_USUARIO]/Desktop/MPIyOpenMP/torneo

# 3. Iniciar aplicaciÃ³n web
make web

# 4. Abrir navegador en: http://localhost:8000/templates/demo.html

# o colocar en un solo comando:
wsl -e bash -c "cd /mnt/c/Users/Usuario/Desktop/MPIyOpenMP/torneo && make web"
```

## ğŸ”§ SoluciÃ³n de Problemas

### Error: "wsl: command not found"
```powershell
# En PowerShell como administrador:
wsl --install -d Ubuntu-22.04
```

### Error: "mpicc no encontrado"
```bash
sudo apt update
sudo apt install libopenmpi-dev openmpi-bin
```

### Error: "cJSON library not found"  
```bash
sudo apt install libcjson-dev
```

### Error: "make: command not found"
```bash
sudo apt install build-essential
```

### La aplicaciÃ³n web no carga
```bash
# Verificar que el servidor estÃ© corriendo
make web

# O manualmente:
cd web && python3 -m http.server 8000
```

### Error: WSL no encuentra el directorio
```bash
# Verificar que estÃ¡s en la ruta correcta, reemplazar "Usuario" por tu nombre:
ls /mnt/c/Users/Usuario/Desktop/MPIyOpenMP/

# Si no existe, verificar tu nombre de usuario en Windows:
ls /mnt/c/Users/
```

## ğŸŒŸ CaracterÃ­sticas TÃ©cnicas

- **Frontend**: HTML5 + CSS3 + JavaScript ES6
- **Backend**: Python HTTP Server (simple)
- **Motor de SimulaciÃ³n**: C con MPI + OpenMP
- **DiseÃ±o**: Mobile-first responsive
- **Efectos**: CSS animations + glassmorphism
- **Compatibilidad**: Todos los navegadores modernos

---

# ğŸ“š **PARTE II: INFORME TÃ‰CNICO**

## ğŸ“– TeorÃ­a: MPI (Message Passing Interface)

### Â¿QuÃ© es MPI?

**MPI (Message Passing Interface)** es un estÃ¡ndar que define la sintaxis y semÃ¡ntica de funciones de biblioteca para escribir programas paralelos portÃ¡tiles usando el paradigma de paso de mensajes.

### Conceptos Fundamentales

#### ğŸ”„ **Modelo de ProgramaciÃ³n**
- **Procesos Independientes**: Cada proceso tiene su propio espacio de memoria
- **ComunicaciÃ³n ExplÃ­cita**: Los procesos intercambian datos mediante mensajes
- **Escalabilidad**: Puede ejecutarse desde una mÃ¡quina hasta miles de nodos

#### ğŸ“¡ **Tipos de ComunicaciÃ³n**

**1. ComunicaciÃ³n Punto a Punto**
```c
MPI_Send(data, count, datatype, dest, tag, comm);    // EnvÃ­o
MPI_Recv(data, count, datatype, source, tag, comm, status); // RecepciÃ³n
```

**2. ComunicaciÃ³n Colectiva**
```c
MPI_Bcast(data, count, datatype, root, comm);       // DifusiÃ³n
MPI_Reduce(sendbuf, recvbuf, count, datatype, op, root, comm); // ReducciÃ³n
```

### Ventajas de MPI
- âœ… **Escalabilidad**: Desde 2 hasta miles de procesos
- âœ… **Portabilidad**: Funciona en cualquier arquitectura
- âœ… **Flexibilidad**: Control total sobre la comunicaciÃ³n
- âœ… **Rendimiento**: Optimizado para alta performance

### Desventajas de MPI
- âŒ **Complejidad**: Requiere gestiÃ³n manual de comunicaciÃ³n
- âŒ **Debugging**: DifÃ­cil depurar programas distribuidos
- âŒ **Overhead**: Costo de comunicaciÃ³n entre procesos

---

## âš¡ TeorÃ­a: OpenMP (Open Multi-Processing)

### Â¿QuÃ© es OpenMP?

**OpenMP** es una API que soporta programaciÃ³n paralela de memoria compartida en mÃºltiples plataformas. Utiliza un modelo de programaciÃ³n fork-join.

### Conceptos Fundamentales

#### ğŸ§µ **Modelo Fork-Join**
1. **Fork**: El hilo maestro crea un equipo de hilos paralelos
2. **Parallel Work**: Los hilos ejecutan trabajo en paralelo
3. **Join**: Los hilos se sincronizan y terminan, solo queda el maestro

#### ğŸ”§ **Directivas Principales**

**1. CreaciÃ³n de Regiones Paralelas**
```c
#pragma omp parallel
{
    // CÃ³digo ejecutado por todos los hilos
}
```

**2. DistribuciÃ³n de Trabajo**
```c
#pragma omp for
for(int i = 0; i < n; i++) {
    // Iteraciones distribuidas entre hilos
}
```

**3. Secciones CrÃ­ticas**
```c
#pragma omp critical
{
    // Solo un hilo a la vez puede ejecutar esto
}
```

### Ventajas de OpenMP
- âœ… **Simplicidad**: Directivas pragmas fÃ¡ciles de usar
- âœ… **Incremental**: Se puede paralelizar cÃ³digo existente gradualmente
- âœ… **Memoria Compartida**: Acceso directo a variables globales
- âœ… **Portable**: EstÃ¡ndar soportado por mÃºltiples compiladores

### Desventajas de OpenMP
- âŒ **Limitado a SMP**: Solo memoria compartida (una mÃ¡quina)
- âŒ **Race Conditions**: Riesgo de condiciones de carrera
- âŒ **Escalabilidad**: Limitado por el nÃºmero de cores disponibles

---

## ğŸ—ï¸ Arquitectura HÃ­brida del Proyecto

### DiseÃ±o de Dos Niveles

![Arquitectura MPI/OpenMP](/torneo/web/static/img/arquitectura.jpg)

Nuestro proyecto implementa un **modelo hÃ­brido** que combina las fortalezas de ambas tecnologÃ­as:

#### ğŸŒ **Nivel 1: DistribuciÃ³n MPI**
```
Proceso 0: TripulaciÃ³n Mugiwaras
Proceso 1: TripulaciÃ³n Barbanegra  
Proceso 2: TripulaciÃ³n Bestias
Proceso N: TripulaciÃ³n N...
```

**FunciÃ³n**: Cada proceso MPI maneja **una tripulaciÃ³n completa**

#### âš¡ **Nivel 2: ParalelizaciÃ³n OpenMP**
```
Dentro de cada proceso MPI:
â”œâ”€â”€ Hilo 0: Combate Luffy
â”œâ”€â”€ Hilo 1: Combate Zoro
â”œâ”€â”€ Hilo 2: Combate Sanji
â””â”€â”€ Hilo N: Combate N...
```

**FunciÃ³n**: Cada hilo OpenMP simula **un combate individual**

### Flujo de EjecuciÃ³n

#### 1. **InicializaciÃ³n (MPI)**
```c
MPI_Init(&argc, &argv);                    // Configurar entorno MPI
MPI_Comm_rank(MPI_COMM_WORLD, &rank);     // Obtener ID del proceso
```

#### 2. **DistribuciÃ³n de Datos (MPI)**
```c
MPI_Bcast(tripulaciones, sizeof(tripulaciones), MPI_BYTE, 0, MPI_COMM_WORLD);
```

#### 3. **Procesamiento Paralelo (OpenMP)**
```c
#pragma omp parallel
{
    // Cada hilo simula combates en paralelo
    unsigned int seed = time(NULL) ^ omp_get_thread_num() ^ rank;
    // ...simulaciÃ³n de combate...
}
```

#### 4. **SincronizaciÃ³n Local (OpenMP)**
```c
#pragma omp critical
{
    if (poder > poder_local) {
        poder_local = poder;
        ganador_local = j;
    }
}
```

#### 5. **AgregaciÃ³n Global (MPI)**
```c
MPI_Reduce(&in, &out, 1, MPI_2INT, MPI_MAXLOC, 0, MPI_COMM_WORLD);
```

### Ventajas de la Arquitectura HÃ­brida

#### ğŸš€ **Escalabilidad Dual**
- **Horizontal (MPI)**: Agregar mÃ¡s nodos/mÃ¡quinas
- **Vertical (OpenMP)**: Utilizar todos los cores por nodo

#### âš™ï¸ **Eficiencia Optimizada**
- **MPI**: Minimiza comunicaciÃ³n entre procesos
- **OpenMP**: Maximiza uso de memoria compartida local


---

## ğŸ“Š AnÃ¡lisis de Rendimiento

### MÃ©tricas de ParalelizaciÃ³n

#### **Speedup TeÃ³rico**
```
Speedup = T_secuencial / T_paralelo
```

#### **Eficiencia**
```
Eficiencia = Speedup / NÃºmero_de_Procesadores
```

### Casos de Uso Ã“ptimos

#### ğŸ¯ **MPI es Ideal Para**:
- Problemas distribuibles por tripulaciones
- Sistemas con mÃºltiples nodos
- Aplicaciones que requieren escalabilidad masiva

#### ğŸ¯ **OpenMP es Ideal Para**:
- Combates simultÃ¡neos dentro de tripulaciones
- Sistemas multi-core
- ParalelizaciÃ³n rÃ¡pida de loops

### Limitaciones y Consideraciones

#### ğŸš§ **Bottlenecks Potenciales**:
1. **ComunicaciÃ³n MPI**: Overhead en `MPI_Reduce`
2. **SincronizaciÃ³n OpenMP**: ContenciÃ³n en secciones crÃ­ticas
3. **Balanceado de Carga**: Diferencias en nÃºmero de personajes por tripulaciÃ³n

#### ğŸ’¡ **Optimizaciones Implementadas**:
- Semillas de aleatoriedad Ãºnicas por hilo
- MinimizaciÃ³n de comunicaciÃ³n MPI
- Uso eficiente de secciones crÃ­ticas

---

## ğŸ“ Conclusiones

Este proyecto demuestra exitosamente:

1. **IntegraciÃ³n MPI/OpenMP**: Modelo hÃ­brido funcional
2. **AplicaciÃ³n PrÃ¡ctica**: Conceptos teÃ³ricos en contexto divertido
3. **Escalabilidad**: Desde laboratorio hasta clusters HPC
4. **Portabilidad**: Funciona en Windows, Linux, macOS

---